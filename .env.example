# Attest Framework — Environment Configuration
# Copy to .env and fill in your values: cp .env.example .env

# ── Provider API Keys ──
# At minimum, set ATTEST_OPENAI_API_KEY to enable Layers 5-6.
ATTEST_OPENAI_API_KEY=
ATTEST_ANTHROPIC_API_KEY=
ATTEST_GEMINI_API_KEY=

# Ollama requires no key — just the base URL.
ATTEST_OLLAMA_BASE_URL=http://localhost:11434

# ── Embedding (Layer 5) ──
# Provider: "auto" (uses OpenAI if key present), "openai", or "onnx"
ATTEST_EMBEDDING_PROVIDER=auto

# ── LLM Judge (Layer 6) ──
# Implemented: openai. Planned v0.4: anthropic, gemini, ollama
# Setting an unimplemented provider causes a startup error.
ATTEST_JUDGE_PROVIDER=
# Override the default judge model (provider-specific).
ATTEST_JUDGE_MODEL=
# Judge timeout in seconds (default: 30).
ATTEST_JUDGE_TIMEOUT_S=30
# Judge rate limiting (overrides defaults: 60 RPM, burst 10).
# ATTEST_JUDGE_RPM=60
# ATTEST_JUDGE_BURST=10

# ── Cache ──
ATTEST_CACHE_DIR=~/.attest/cache
ATTEST_EMBEDDING_CACHE_MAX_MB=500

# ── ONNX Local Embedding (optional, requires onnx build tag) ──
ATTEST_MODEL_DIR=~/.attest/models

# ── Engine Binary ──
# Override path to attest-engine binary (skips all discovery).
ATTEST_ENGINE_PATH=
# Set to 1 to disable auto-download of the engine binary.
# When disabled, you must build from source or download manually.
# ATTEST_ENGINE_NO_DOWNLOAD=

# ── Rate Limiting ──
# Requests per minute per provider.
ATTEST_RATE_LIMIT_OPENAI=60
ATTEST_RATE_LIMIT_ANTHROPIC=60
ATTEST_RATE_LIMIT_GEMINI=60
